{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "       <img src=\"http://www.uoc.edu/portal/_resources/common/imatges/marca_UOC/UOC_Masterbrand.jpg\", align=\"left\">\n",
    "    </div>\n",
    "</div>\n",
    "\n",
    "<div style=\"float: right; width: 50%;\">\n",
    "    <p style=\"margin: 0; padding-top: 22px; text-align:right;\">22.501 · Fundamentos de Programación</p>\n",
    "    <p style=\"margin: 0; text-align:right;\">Grado en Ciencia de Datos Aplicada</p>\n",
    "    <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "<div style=\"width: 100%; clear: both;\">\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb7kfS_kD8-K"
   },
   "source": [
    "Fundamentos de Programación\n",
    "============================\n",
    "\n",
    "PEC 7 - Introducción al análisis de datos en Python\n",
    "-----------------------------------------------------\n",
    "\n",
    "En este Notebook se encontraréis el conjunto de actividades evaluables como PEC de la asignatura. Veréis que cada una de ellas tiene asociada una puntuación, que indica el peso que tiene la actividad sobre la nota final de la PEC. Adicionalmente, hay algún ejercicio opcional, que no tiene puntuación dentro de la PEC, pero que se valora al final del semestre de cara a conceder las matrículas de honor y redondear las notas finales. Podréis sacar la máxima nota de la PEC sin necesidad de hacer estos ejercicios. El objetivo de estos ejercicios es que sirvan como pequeño reto para los estudiantes que quieran profundizar en el contenido de la asignatura.\n",
    "\n",
    "Veréis que todas las actividades de la PEC tienen una etiqueta, que indica los recursos necesarios para llevarla a cabo. Hay tres posibles etiquetas:\n",
    "\n",
    "* $\\color{green}{\\text{NM}}$ **Sólo materiales**: las herramientas necesarias para realizar la actividad se pueden encontrar en los materiales de la asignatura.\n",
    "\n",
    "* $\\color{orange}{\\text{EG}}$ **Consulta externa guiada**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, pero el enunciado contiene indicaciones de dónde o cómo encontrar la información adicional necesaria para resolver la actividad.\n",
    "\n",
    "* $\\color{red}{\\text{EI}}$ **Consulta externa independiente**: la actividad puede requerir hacer uso de herramientas que no se encuentran en los materiales de la asignatura, y el enunciado puede no incluir la descripción de dónde o cómo encontrar esta información adicional. Será necesario que el estudiante busque esta información utilizando los recursos que se han explicado en la asignatura.\n",
    "\n",
    "Es importante notar que estas etiquetas no indican el nivel de dificultad del ejercicio, sino únicamente la necesidad de consulta de documentación externa para su resolución. Además, recordad que las **etiquetas son informativas**, pero podréis consultar referencias externas en cualquier momento (aunque no se indique explícitamente) o puede ser que podáis hacer una actividad sin consultar ningún tipo de documentación. Por ejemplo, para resolver una actividad que sólo requiera los materiales de la asignatura, puedéis consultar referencias externas si queréis, ya sea tanto para ayudaros en la resolución como para ampliar el conocimiento!\n",
    "\n",
    "En cuanto a la consulta de documentación externa en la resolución de los ejercicios, recordad **citar siempre la bibliografía utilizada** para resolver cada actividad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNG2gSLygo_F"
   },
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5ZvJU93go8H"
   },
   "source": [
    "En la primera parte de la PEC vamos a trabajar con dos datasets, `movie.csv` y `ratings.csv`, que se encuentran en la carpeta `data`. **(2 puntos)**\n",
    "\n",
    "a) Carga los dos datasets e imprime por pantalla sus dimensiones, así como el nombre de las columnas. Muestra también las 5 primeras filas de cada dataset. $\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77KUKMqGwjXg"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPEtMh2rgo5U"
   },
   "source": [
    "b1) En el dataset movie, hay información sobre el año de la película en la columna `title`. Extrae la fecha de la película y crea una nueva columna con esta información.\n",
    "\n",
    "¿En cuantas películas no tenemos información sobre el año? Muestra las filas por pantalla. \n",
    "\n",
    "**Nota**: Ten en cuenta que solo nos interesa extraer los números entre paréntesis. Si hay algún texto, no lo queremos. Revisa también que los valores tengan sentido, si hay años que no sean posibles, sustitúyelos por NaNs. \n",
    "\n",
    "$\\color{orange}{\\text{EG}}$ **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FHYUN_hzwkgz"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPtTUk_TuDOd"
   },
   "source": [
    "b2) Por otro lado, en la columna de `genres`, hay películas con más de un género. Para simplificar, queremos quedarnos solo con el primero. Crea una nueva columna con esta información. \n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "focCYq3wwliW"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS8qjrbSuJAX"
   },
   "source": [
    "b3) Muestra las 5 primeras filas del dataset movie con las 2 nuevas columnas.\n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1yTzdhAwmVY"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1sWIWO9uRbB"
   },
   "source": [
    "c1) En el dataset `ratings` tenemos la puntuación que cada usuario ha dado a las películas. Para poder integrar esta información en el dataframe `movies`, calcula la puntuación media por película y añadela como nueva columna al dataframe `movies`.\n",
    "\n",
    "**Nota**: Redondea el valor para que solo tenga **2 decimales**. \n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6RhnJ0JwnAj"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jvKgq_d4uVKX"
   },
   "source": [
    "c2) Hay alguna película sin puntuación? Cuenta cuantas hay y asígnales un valor de 0.\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7nKfnuuwnxB"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ftds13N_uakk"
   },
   "source": [
    "d) En el dataset de `rating` también podemos extraer cuantas valoraciones tiene cada película. Añade esta información al dataframe de `movies`. $\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zR1d1jbdwobR"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKvNkgeEgo3V"
   },
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Una vez tenemos el dataset de movie preparado y con la información addicional, vamos a explorarlo un poco. **(1 punto)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPS3x_gXuiZE"
   },
   "source": [
    "a) Calcula la puntuación media por año y ordénalos de mayor a menor. Muestra el top10 de años (con mayor puntuación) usando un barplot. \n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.5 puntos)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcXANkkrwpZr"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bkxsS7Wkup42"
   },
   "source": [
    "b) Calcula también la puntuación media por género. ¿Qué género tiene la mayor puntuación media, y cuál la peor? \n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NdeU3cB2wqLe"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTDry2xOuuM0"
   },
   "source": [
    "c) ¿Qué película tiene más valoraciones? Muestra el título de la película y el número de valoraciones. \n",
    "\n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SMWa2izwq9v"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jiu1WOx6go1E"
   },
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "En el dataset ampliado de movies tenemos información sobre el año, la categoría, la puntuación y el número de valoraciones por película. Con toda esta información, queremos utilizar un algoritmo de clustering para agrupar las películas en diferentes grupos según sus características. Para lograrlo, vamos a utilizar el algoritmo **KMeans**. \n",
    "\n",
    "(**2 puntos**)\n",
    "\n",
    "\n",
    "a) Primero de todo, vamos a quedarnos solo con las características que nos interesan, en este caso, `movieId`, `year`, `principal_genre`, `rating` y `userId`. Muestra el nuevo dataframe por pantalla. $\\color{green}{\\text{NM}}$ (**0.25 puntos**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWku2CN9wrsq"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWsZjzBfu8j0"
   },
   "source": [
    "b) Para usar el algoritmo de KMeans, no podemos tener NaNs. Comprueba si hay NaNs en el dataset. ¿Qué estratégias puedes llevar a cabo para solucionar este problema? Da 2 posibilidades, razona cuál escogerías en este caso y aplícala. \n",
    "$\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZpY3GJRwsX9"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQcyOW71vL3J"
   },
   "source": [
    "c) Los elementos de la columna del género principal, al ser un string, no se pueden usar directamente en el KMeans, sino que se tienen que transformar a valor numérico. ¿Qué tipo de transformación es más adecuada para esto? Aplícala. $\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQGgz9SCwtib"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uw8fCHW9vP9G"
   },
   "source": [
    "d) Antes de aplicar el KMeans, normaliza los datos numéricos utilizando la función MinMaxScaler. ¿Por que razón es importante hacer esta transformación? $\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Br47-cp3wuXY"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XC-ZWnrovVbO"
   },
   "source": [
    "e) Uno de los problemas de los métodos no supervisados es identificar el número óptimo de clusters. Para poder estimar esta número óptimo, se utiliza frecuentemente el método de Elbow. Busca información sobre este método y utilízalo. ¿Cuál es el número óptimo de clusters? Considera un rango entre 1 y 20 clusters. $\\color{red}{\\text{EI}}$ **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jqg0tDEiwvMy"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9mui_envcpS"
   },
   "source": [
    "f) Aplica el método KMeans especificando el número óptimo de clusters obtenido en el apartado anterior. Cuantas películas hay en cada cluster? $\\color{green}{\\text{NM}}$ **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LE8WlbvvwwYy"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zH2mdUM4vshU"
   },
   "source": [
    "### Ejercicio opcional\n",
    "\n",
    "Una plataforma de contenido digital nos ha contactado para que le ayudemos a hacer un algoritmo que permita recomendar películas, basándonos en las valoraciones de los usuarios de esta plataforma. Para demostrar que estamos preparados para tal desafío, vamos a usar los datos de películas y valoraciones del ejercicio anterior para construir un sistema de recomendación. \n",
    "\n",
    "a) Utilizando el dataset de `ratings.csv` original, crea una `pivot table` que tenga **movieID** como filas, **userID** como columnas, y las valoraciones (**rating**) como el valor. Esta nueva tabla nos dará información de la valoración que ha puesto cada usuario a cada película."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOYkB4F1wxTg"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_VaNeAFvyO7"
   },
   "source": [
    "b) Los usuarios no puntúan todas las películas, por eso tenemos bastantes NaNs. Sustituye estos NaNs por 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SYVFK1qhwx9I"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCs_iMGkv2Vc"
   },
   "source": [
    "c) Como podéis ver, la matriz resultante tiene muchos 0, ya que hay muchas películas que no se puntúan. Para que esto no nos afecte en el análisis, vamos a quedarnos solo con aquellos usuarios que han puntuado más de 10 veces y aquellas películas valoradas más de 50 veces. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgM5RUhzwymT"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LplYSU53v-Vp"
   },
   "source": [
    "d) Para construír el algoritmo de recomendación, necesitamos comprimir el dataframe en una matriz esparza (*sparce matrix*). Para hacerlo, vamos a usar la función [csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SMh7hwuxwzWC"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFL6MY5ZwJNJ"
   },
   "source": [
    "e) A continuación, haz un reseteo de los índices (con **reset_index**) del dataframe anterior, ya que vamos a necesitarlo en los siguientes apartados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56Y_rP1xw0B7"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZhLtvoFwMUC"
   },
   "source": [
    "f) Finalmente, vamos a entrenar el algoritmo no supervisado de [K-Nearest Neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html). Como parámetros, vamos a usar la metrica `cosine` y 20 vecinos (*n_neighbors*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "grErsLddw0nU"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_aFZ-80wbC6"
   },
   "source": [
    "g) Para comprobar que hemos seguido los pasos correctos, vamos a usar la función `get_movie_recommendation` para sacar 5 películas recomendadas basadas en **Matrix**. Estudia bien la función para entender cuáles son los inputs necesarios y como se relacionan con los pasos que hemos hecho anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZdJuXUwyqUKH"
   },
   "outputs": [],
   "source": [
    "def get_movie_recommendation(\n",
    "    movies_df,\n",
    "    user_movie_ratings_df,\n",
    "    movie_name, \n",
    "    n_movies_to_reccomend, \n",
    "    model\n",
    "):\n",
    "    \"\"\"\n",
    "    movies_df: DataFrame de películas original (es decir, movie.csv)\n",
    "    user_movie_ratings_df: DataFrame de la pivot table después del reseteo de los índices\n",
    "    movie_name: nombre de la película de la cual queremos recomendaciones\n",
    "    n_movies_to_reccomend: número de recomendaciones (e.g. 10)\n",
    "    model: modelo NN entrenado con la matriz esparza (csr_matrix)\n",
    "    \"\"\"\n",
    "    # Buscamos películas que contengan el nombre que hemos indicado\n",
    "    movie_list = movies_df[movies_df['title'].str.contains(movie_name)]\n",
    "    # Si hay\n",
    "    if len(movie_list):\n",
    "        # Nos quedamos con el índice la 1a película de la lista\n",
    "        movie_idx= movie_list.iloc[0]['movieId']\n",
    "        # Mostramos por pantalla la película que vamos a usar como referencia\n",
    "        print(f\"Recommendations for {movie_list.iloc[0]['title']}\\n\")\n",
    "        # Miramos a que índice del df de la pivot table corresponde este movieId\n",
    "        movie_idx = user_movie_ratings_df[user_movie_ratings_df['movieId'] == movie_idx].index[0]\n",
    "        # Calculamos la distancia y los índices aplicando el KNN a esta película\n",
    "        distances , indices = model.kneighbors(csr_data[movie_idx],n_neighbors=n_movies_to_reccomend+1)    \n",
    "        # Ordenamos los índices por la distancia para tener los vecinos más similares\n",
    "        rec_movie_indices = sorted(list(zip(indices.squeeze().tolist(),distances.squeeze().tolist())),key=lambda x: x[1])[:0:-1]\n",
    "        # Creamos un lista para guardar los resultados\n",
    "        recommend_frame = []\n",
    "        # Vamos a guardar la información de cada película recomendada\n",
    "        for val in rec_movie_indices:\n",
    "            # Sacamos el movieId de la película recomendada\n",
    "            movie_idx = user_movie_ratings_df.iloc[val[0]]['movieId']\n",
    "            # Miramos a que índice corresponde de movies_df\n",
    "            idx = movies_df[movies_df['movieId'] == movie_idx].index\n",
    "            # Guardamos el título y la distancia de la película\n",
    "            recommend_frame.append({'Title':movies_df.iloc[idx]['title'].values[0],'Distance':val[1]})\n",
    "        # Transformamos la lista a df\n",
    "        df = pd.DataFrame(recommend_frame,index=range(1,n_movies_to_reccomend+1))\n",
    "        return df\n",
    "    else:\n",
    "        return \"No movies found. Please check your input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eTyV7VSw3sz"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMq32SmMgorx"
   },
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Amb00nCtgopi"
   },
   "source": [
    "A continuación vamos a cambiar a un dataset mucho más grande con más películas de todas las épocas. Su nombre es `movies_long.csv` y lo podréis encontrar en la carpeta `data`. **(1.25 puntos)**\n",
    "\n",
    "(a) Carga el *dataset* e imprime por pantalla sus dimensiones, así como el nombre de las columnas, su tipo y el número de valores no perdidos que contienen. Imprime también las diez primeras filas para ver qué tipo de datos contiene. Elimina las filas que contengan valores perdidos, o NaN, del dataset, para evitar problemas. $\\color{green}{\\text{NM}}$ **(0.5 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IrbEMBKz19U9"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w72i7S0O1smW"
   },
   "source": [
    "(b) Queremos centrarnos en en valor de las ganancias totales de las películas (dadas por la columna 'gross') y ver si podemos encontrar una manera de predecirlo con los datos de los que disponemos. Primero, visualiza la correlación entre todas las variables y grafícala utilizando la librería `seaborn`. Verás que no todas las variables se han añadido en la gráfica. ¿Por qué es? **(0.5 puntos)**  $\\color{green}{\\text{NM}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCabKjmsS7Vf"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BBYYolL62t70"
   },
   "source": [
    "(c) Muestra una lista con las variables que más se correlacionan con 'gross', ordenada de mayor correlación a menor correlación.   $\\color{green}{\\text{NM}}$ **(0.25 puntos)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sZNywF92_7p"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-PMak2z3GaU"
   },
   "source": [
    "### Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udc9N6gT3JaK"
   },
   "source": [
    "A continuación vamos a intentar utilizar la técnica de PCA para reducir la dimensionalidad del dataset. Hemos visto en el apartado anterior que muchas variables están muy correlacionadas con 'gross', por lo que es bastante probable que exista información redundante. **Nota:** aunque PCA se puede aplicar sin problemas en este caso, realmente no es extremadamente útil, ya que tenemos un número bastante pequeño de \"features\". PCA es sobre todo útil cuando tenemos muchas dimensiones (o \"features\") y queremos reducirlo a un número más adecuado para el análisis rápido. En nuestro caso, utilizamos un dataset más pequeño para que sea más sencillo. **(2 puntos)** \n",
    "\n",
    "(a) Antes de ajustar el modelo de PCA, tipifica los datos con `sklearn.preprocessing.StandardScaler`, para lo que primero tendrás que seleccionar **sólo las columnas que contienen valores numéricos**. ¿Qué hace esta función? Calcula el valor medio y la desviación típica de los datos tipificados **antes y después** de aplicar la función para cada de las variables. **(0.5 puntos)**  $\\color{green}{\\text{NM}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mqqXCmbkhJ4"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RuH32rJBgohH"
   },
   "source": [
    "(b) Ajusta el modelo de componentes principales sobre los datos tipificados, pero limita el número de componentes principales a 2. ¿Cuánta variabilidad explican estas dos componentes? **(0.5 puntos)**  $\\color{green}{\\text{NM}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mEPi84ITDWu"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrFdE_K5rlCS"
   },
   "source": [
    "(c) Recorre utilizando bucles *for* las componentes principales (también llamadas *loadings*) del modelo PCA e imprime en pantalla sus valores para sacar conclusiones sobre qué variables están incluidas en qué componente principal. ¿Qué variables tienen más influencia en la primera componente? ¿Y en la segunda? **(1 punto)**  $\\color{green}{\\text{NM}}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-R7nFjmYTHja"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hITqXrm-s0xR"
   },
   "source": [
    "### Ejercicio 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5CC7YxDSs0vB"
   },
   "source": [
    "Finalmente, en este ejercicio vamos a aplicar una [regresión lineal](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) para intentar predecir el 'gross income' de una película utilizando todas estas variables. **(1.75 puntos)** \n",
    "\n",
    "(a) Utiliza la función de `Scikit-Learn` proporcionada arriba para realizar una regresión lineal para predecir el 'gross income' según el resto de variables numéricas. Divide los datos en test y train (con un porcentaje de 20% para el test) y luego evalúa los resultados en los datos de test, imprimiendo el pantalla el R2 del modelo. ¿Cómo lo interpretas? **(0.5 puntos)** $\\color{orange}{\\text{EG}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzrYCGF550gz"
   },
   "outputs": [],
   "source": [
    " # Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCoS6VZ96h-l"
   },
   "source": [
    "(b) Queremos ver ahora si podemos utilizar el género de la película para predecir juto con el resto de \"features\" el 'gross income' de las películas, ya que pensamos que podría tener una gran influencia. Modifica tu código anterior ligeramente para añadir como variable predictora el género junto al resto de variables numéricas. Luego intenta hacer la regresión lineal. Te devolverá un error. ¿Por qué ocurre esto? **(0.25 puntos)**  $\\color{green}{\\text{NM}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObKqRdfU689B"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2obZSQKz7aMX"
   },
   "source": [
    "(c) Claramente lo tenemos que hacer de otra manera. Vamos a crear \"dummy variables\" para los datos del género de la película y poder realizar la regresión lineal. Utiliza la función [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) de `pandas` para ello. Investiga en internet para qué sirve este procedimiento de \"dummy variables\". Una vez hecho esto, vuelve a realizar el modelo de regresión lineal utilizando las variables numéricas y el género de la película e imprime el R2. ¿Merece la pena, viendo este R2, incluir el género en nuestro modelo? **(0.5 puntos)** $\\color{orange}{\\text{EG}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zWGmSWC7Y4N"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBk-E1Sm8rvq"
   },
   "source": [
    "(d) Si ejecutas las celdas anteriores varias veces, verás el que R2 que devuelve puede ser ligeramente diferente cada vez. Esto es porque los datos de train y test se generan aleatoriamente en cada split (a no ser que hayas fijado una random seed) y al hacer ajuste al modelo en datos ligeramente diferentes, los resultados pueden variar un poco. Para ser más robustos, podemos hacer una validación cruzada de `KFold` con la función [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html), `shuffle = True` y 5 validaciones (usa sólo las variables numéricas, sin el género). **(0.5 puntos)** $\\color{orange}{\\text{EG}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjiTH1epTUUH"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVRCsi2296Nk"
   },
   "source": [
    "### Ejercicio opcional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CS5G6SEC9-8N"
   },
   "source": [
    "Continuando a partir del ejercicio anterior, queremos hacer un \"ablation study\" o \"estudio de ablación\", que consiste en un análisis de la eliminación progresiva de variables o características en un modelo para evaluar su impacto en el rendimiento o la capacidad predictiva del modelo. Utilizando sólo las variables numéricas, haz un estudio de ablación donde realizas la validación cruzada con `KFold` con cinco validaciones de las variables numéricas del dataset, eliminando una diferente en cada iteración. Compara el R2 del modelo reducido (con una variable menos) y el cambio que produce en el R2 con respecto al modelo completo. ¿Qué conclusiones sacas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDiZrMcF9-dj"
   },
   "outputs": [],
   "source": [
    "# Respuesta"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
